{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Memory\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "from pre_processing.preprocessing import Pre_Processing\n",
    "from transfer_learning.tl_classifier import TL_Classifier\n",
    "from transfer_learning import TLSplitter, encode_datasets\n",
    "from loaddata import Dataset_Left_Right_MI\n",
    "\n",
    "# 设置参数\n",
    "dataset_name = 'Pan2023'\n",
    "fs = 250\n",
    "freqband = [8,30]\n",
    "datapath = r'E:\\工作进展\\小论文2023会议\\数据处理python\\datasets'\n",
    "\n",
    "# 加载数据\n",
    "dataset = Dataset_Left_Right_MI(dataset_name,fs,fmin=freqband[0],fmax=freqband[1],tmin=0,tmax=4,path=datapath)\n",
    "sdata, slabel = [], []\n",
    "for i in range(1,4):    \n",
    "    data, label = dataset.get_data([i])\n",
    "    sdata.append(data)\n",
    "    slabel.append(label)\n",
    "    \n",
    "X, y_enc, domain =encode_datasets(sdata, slabel)\n",
    "print(X.shape, y_enc.shape, len(domain))\n",
    "print(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Memory\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "from pre_processing.preprocessing import Pre_Processing\n",
    "from transfer_learning.tl_classifier import TL_Classifier\n",
    "from transfer_learning import TLSplitter, encode_datasets\n",
    "from loaddata import Dataset_Left_Right_MI\n",
    "\n",
    "# 设置参数\n",
    "dataset_name = 'Pan2023'\n",
    "fs = 250\n",
    "freqband = [8,30]\n",
    "datapath = r'E:\\工作进展\\小论文2023会议\\数据处理python\\datasets'\n",
    "\n",
    "# 加载数据\n",
    "dataset = Dataset_Left_Right_MI(dataset_name,fs,fmin=freqband[0],fmax=freqband[1],tmin=0,tmax=4,path=datapath)\n",
    "sdata, slabel = [], []\n",
    "for i in range(1,4):    \n",
    "    data, label = dataset.get_data([i])\n",
    "    sdata.append(data)\n",
    "    slabel.append(label)\n",
    "    \n",
    "X, y_enc, domain =encode_datasets(sdata, slabel)\n",
    "print(X.shape, y_enc.shape, len(domain))\n",
    "print(domain)\n",
    "\n",
    "# 设置缓存目录\n",
    "cachedir = '../my_cache_directory'\n",
    "memory = Memory(cachedir, verbose=0)\n",
    "\n",
    "# 实例化模型\n",
    "preprocess = Pre_Processing(fs_new=160, fs_old=250, \n",
    "                       n_channels=np.arange(0, 28), \n",
    "                       start_time=0.5, end_time=3.5,\n",
    "                       lowcut=None, highcut=None, )\n",
    "Model = TL_Classifier(dpa_method='EA', \n",
    "                      fee_method='CSP', \n",
    "                      fes_method='MIC-K', \n",
    "                      clf_method='SVM',\n",
    "                      pre_est=preprocess.process,\n",
    "                      memory=memory,\n",
    "                      target_domain=domain[0],\n",
    "                      )\n",
    "\n",
    "# 交叉验证\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "tl_cv = TLSplitter(target_domain=domain[0], cv=cv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = TL_Classifier(dpa_method='RPA', \n",
    "                      fee_method='TS', \n",
    "                      fes_method='MIC-K', \n",
    "                      clf_method='LR',\n",
    "                      pre_est=preprocess.process,\n",
    "                      memory=memory,\n",
    "                      target_domain=domain[0],\n",
    "                      )\n",
    "a = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for train, test in tl_cv.split(X, y_enc):\n",
    "    X_train, y_train = X[train], y_enc[train]\n",
    "    X_test, y_test = X[test], y_enc[test]\n",
    "    Model.fit(X_train, y_train)\n",
    "    score = Model.score(X_test, y_test)\n",
    "    acc.append(score)\n",
    "    print(\"Score: %0.2f\" % score)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(acc), np.std(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(Model, X, y_enc, cv=tl_cv, n_jobs=15)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning.csp import FBCSP\n",
    "from utils import check_pipeline_compatibility as cpc\n",
    "from utils import ensure_pipeline\n",
    "\n",
    "est = FBCSP(fs=250)\n",
    "\n",
    "print(callable(est))\n",
    "print(cpc(est))\n",
    "print(ensure_pipeline(est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from transfer_learning import TLSplitter\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "tl_cv = TLSplitter(target_domain='S1', cv=cv, no_calibration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "cv = StratifiedShuffleSplit(n_splits=10, random_state=42)\n",
    "tl_cv = TLSplitter(target_domain='S1', cv=cv, no_calibration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_cv.cv.train_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tl_cv.cv.train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in tl_cv.split(X, y_enc):\n",
    "    print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import signature\n",
    "from transfer_learning.utilities import *\n",
    "\n",
    "# 字典存储分类器及其类\n",
    "classifiers = {\n",
    "    'svm': SVC,\n",
    "    'lda': LDA,\n",
    "    'lr':  LR,\n",
    "    'knn': KNN,\n",
    "    'dtc': DTC,\n",
    "    'rfc': RFC,\n",
    "    'etc': ETC,\n",
    "    'abc': ABC,\n",
    "    'gbc': GBC,\n",
    "    'gnb': GNB,\n",
    "    'mlp': MLP,\n",
    "    'csp': CSP,\n",
    "    'trcsp': TRCSP,\n",
    "    'mdm': MDM,\n",
    "    'fgmdm': FgMDM,\n",
    "    'tsclassifier': TSclassifier,\n",
    "    'rknn': RKNN,\n",
    "    'rksvm': RKSVM,\n",
    "    'ts': TS,\n",
    "    'tlcenter': TLCenter,\n",
    "    'tlstretch': TLStretch,\n",
    "    'tlrotate': TLRotate,\n",
    "    'rct': RCT,\n",
    "    'str': STR,\n",
    "    'rot': ROT,\n",
    "}\n",
    "\n",
    "def supports_sample_weight(clf_name):\n",
    "    clf_class = classifiers.get(clf_name.lower())\n",
    "    if clf_class is None:\n",
    "        raise ValueError(f\"Classifier '{clf_name}' is not recognized.\")\n",
    "    \n",
    "    # Get the fit method of the classifier\n",
    "    \n",
    "    fit_method = getattr(clf_class(), 'fit')\n",
    "    \n",
    "    # Get the parameters of the fit method\n",
    "    params = signature(fit_method).parameters\n",
    "    \n",
    "    return 'sample_weight' in params\n",
    "\n",
    "# 测试函数\n",
    "print('Method svm', supports_sample_weight('svm'))  # True\n",
    "print('Method lda', supports_sample_weight('lda'))  # False\n",
    "print('Method lr', supports_sample_weight('lr'))  # False \n",
    "print('Method knn', supports_sample_weight('knn'))  # False\n",
    "print('Method dtc', supports_sample_weight('dtc'))  # False\n",
    "print('Method rfc', supports_sample_weight('rfc'))  # False\n",
    "print('Method etc', supports_sample_weight('etc'))  # False\n",
    "print('Method abc', supports_sample_weight('abc'))  # False\n",
    "print('Method gbc', supports_sample_weight('gbc'))  # False\n",
    "print('Method gnb', supports_sample_weight('gnb'))  # False\n",
    "print('Method mlp', supports_sample_weight('mlp'))  # False\n",
    "print('Method csp', supports_sample_weight('csp'))  # False\n",
    "print('Method trcsp', supports_sample_weight('trcsp'))  # False\n",
    "print('Method mdm', supports_sample_weight('mdm'))  # False\n",
    "print('Method fgmdm', supports_sample_weight('fgmdm'))  # False\n",
    "print('Method tsclassifier', supports_sample_weight('tsclassifier'))  # False\n",
    "print('Method rknn', supports_sample_weight('rknn'))  # False\n",
    "print('Method rksvm', supports_sample_weight('rksvm'))  # False\n",
    "print('Method ts', supports_sample_weight('ts'))  # False\n",
    "print('Method tlcenter', supports_sample_weight('tlcenter'))  # False\n",
    "print('Method rct', supports_sample_weight('rct'))  # False\n",
    "print('Method str', supports_sample_weight('str'))  # False\n",
    "print('Method rot', supports_sample_weight('rot'))  # False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transfer_learning.rpa import TLCenter_online\n",
    "from pyriemann.utils.covariance import covariances\n",
    "import numpy as np\n",
    "\n",
    "X = np.random.rand(20, 28, 28)\n",
    "C = covariances(X,'lwf')\n",
    "TLCenter_online().get_recenter(C, sample_weight=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transfer_learning.tl_classifier import TL_Classifier\n",
    "from utils import extract_dict_keys\n",
    "DPA_METHODS = extract_dict_keys('transfer_learning.tl_classifier', 'TL_Classifier', 'check_dpa', 'prealignments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.rand(5, 10, 20) \n",
    "input_shape =X.shape\n",
    "sample_count, channel_count, time_point_count = input_shape[-3], input_shape[-2], input_shape[-1]\n",
    "new_sample_count = np.prod(input_shape[:-3]) * sample_count\n",
    "print(new_sample_count)\n",
    "\n",
    "new_X = X.reshape((new_sample_count, channel_count, time_point_count))\n",
    "# 检查new_X是否与X相同\n",
    "print(np.all(new_X == X.reshape((new_sample_count, channel_count, time_point_count))))\n",
    "print(new_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y = np.random.randint(0, 2, (5, 1)) \n",
    "print(y)\n",
    "new_y = np.repeat(y, 2, axis=0)\n",
    "print(new_y)\n",
    "new_y = np.tile(y, 2)\n",
    "print(new_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
