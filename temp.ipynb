{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from pyriemann.utils.distance import distance_riemann\n",
    "from pyriemann.classification import MDM, FgMDM\n",
    "from machine_learning import TSclassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.pipeline import make_pipeline, Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaddata import Dataset_Left_Right_MI\n",
    "dataset_name = 'Pan2023'\n",
    "\n",
    "fs = 250\n",
    "freqband = [8,30]\n",
    "datapath = r'E:\\工作进展\\小论文2023会议\\数据处理python\\datasets'\n",
    "\n",
    "dataset = Dataset_Left_Right_MI(dataset_name,fs,fmin=freqband[0],fmax=freqband[1],tmin=0,tmax=4,path=datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=50\n",
    "ABC_algorithm=\"SAMME\"\n",
    "\n",
    "clf0 = MDM()\n",
    "clf1 = AdaBoostClassifier(clf0,n_estimators=n_estimators,algorithm=ABC_algorithm)\n",
    "\n",
    "clf2 = FgMDM()\n",
    "clf3 = AdaBoostClassifier(clf2,n_estimators=n_estimators,algorithm=ABC_algorithm)\n",
    "\n",
    "clf4 = TSclassifier(clf=LDA())\n",
    "clf5 = AdaBoostClassifier(clf4,n_estimators=n_estimators,algorithm=ABC_algorithm)\n",
    "\n",
    "clf6 = TSclassifier()\n",
    "clf7 = AdaBoostClassifier(clf6,n_estimators=n_estimators,algorithm=ABC_algorithm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "# cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyriemann.estimation import Covariances\n",
    "data, label = dataset.get_data([1])\n",
    "data = Covariances(estimator='lwf').transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比较不同分类器的效果\n",
    "\n",
    "n_jobs = 15\n",
    "\n",
    "# 1.MDM\n",
    "scores = cross_val_score(clf0, data, label, cv=cv, n_jobs=n_jobs)\n",
    "print(\"MDM Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# 2.AdaBoost-MDM\n",
    "scores = cross_val_score(clf1, data, label, cv=cv, n_jobs=n_jobs)\n",
    "print(\"Adaboost-MDM Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# 3.FgMDM\n",
    "scores = cross_val_score(clf2, data, label, cv=cv, n_jobs=n_jobs)\n",
    "print(\"FgMDM Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# 4.AdaBoost-FgMDM\n",
    "scores = cross_val_score(clf3, data, label, cv=cv, n_jobs=n_jobs)\n",
    "print(\"AdaBoost-FgMDM Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# 5.TSLDA\n",
    "scores = cross_val_score(clf4, data, label, cv=cv, n_jobs=n_jobs)\n",
    "print(\"TSLDA Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# 6.AdaBoost-TSLDA\n",
    "scores = cross_val_score(clf5, data, label, cv=cv, n_jobs=n_jobs)\n",
    "print(\"AdaBoost-TSLDA Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# 7.TSGLM\n",
    "scores = cross_val_score(clf6, data, label, cv=cv, n_jobs=n_jobs)\n",
    "print(\"TSGLM Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# 8.AdaBoost-TSGLM\n",
    "scores = cross_val_score(clf7, data, label, cv=cv, n_jobs=n_jobs)\n",
    "print(\"AdaBoost-TSGLM Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from joblib import Memory\n",
    "\n",
    "from machine_learning.classifier import svc,lda,lr,knn,dtc,rfc,etc,abc,gbc,gnb,mlp\n",
    "from machine_learning import RiemannCSP as CSP\n",
    "from machine_learning import TS\n",
    "# fee = CSP()\n",
    "fee = TS()\n",
    "\n",
    "# 设置缓存目录\n",
    "cachedir = 'my_cache_directory'\n",
    "memory = Memory(cachedir, verbose=0)\n",
    "\n",
    "clf1 = make_pipeline(fee, svc, memory=memory)\n",
    "scores = cross_val_score(clf1, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier1 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf2 = make_pipeline(fee, lda, memory=memory)\n",
    "scores = cross_val_score(clf2, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier2 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf3 = make_pipeline(fee, lr, memory=memory)\n",
    "scores = cross_val_score(clf3, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier3 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf4 = make_pipeline(fee, knn, memory=memory)\n",
    "scores = cross_val_score(clf4, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier4 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf5 = make_pipeline(fee, dtc, memory=memory)\n",
    "scores = cross_val_score(clf5, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier5 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf6 = make_pipeline(fee, rfc, memory=memory)\n",
    "scores = cross_val_score(clf6, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier6 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf7 = make_pipeline(fee, etc, memory=memory)\n",
    "scores = cross_val_score(clf7, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier7 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf8 = make_pipeline(fee, abc, memory=memory)\n",
    "scores = cross_val_score(clf8, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier8 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf9 = make_pipeline(fee, gbc, memory=memory)\n",
    "scores = cross_val_score(clf9, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier9 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf10 = make_pipeline(fee, gnb, memory=memory)\n",
    "scores = cross_val_score(clf10, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier10 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf11 = make_pipeline(fee, mlp, memory=memory)\n",
    "scores = cross_val_score(clf11, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier12 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from joblib import Memory\n",
    "\n",
    "from machine_learning.classifier import svc,lda,lr,knn,dtc,rfc,etc,abc,gbc,gnb,mlp\n",
    "from machine_learning import TS\n",
    "fee = TS()\n",
    "\n",
    "# 设置缓存目录\n",
    "cachedir = 'my_cache_directory'\n",
    "memory = Memory(cachedir, verbose=0)\n",
    "\n",
    "clf1 = make_pipeline(fee, svc, memory=memory)\n",
    "scores = cross_val_score(clf1, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier1 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf2 = make_pipeline(fee, lda, memory=memory)\n",
    "scores = cross_val_score(clf2, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier2 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf3 = make_pipeline(fee, lr, memory=memory)\n",
    "scores = cross_val_score(clf3, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier3 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf4 = make_pipeline(fee, knn, memory=memory)\n",
    "scores = cross_val_score(clf4, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier4 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf5 = make_pipeline(fee, dtc, memory=memory)\n",
    "scores = cross_val_score(clf5, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier5 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf6 = make_pipeline(fee, rfc, memory=memory)\n",
    "scores = cross_val_score(clf6, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier6 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf7 = make_pipeline(fee, etc, memory=memory)\n",
    "scores = cross_val_score(clf7, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier7 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf8 = make_pipeline(fee, abc, memory=memory)\n",
    "scores = cross_val_score(clf8, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier8 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf9 = make_pipeline(fee, gbc, memory=memory)\n",
    "scores = cross_val_score(clf9, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier9 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf10 = make_pipeline(fee, gnb, memory=memory)\n",
    "scores = cross_val_score(clf10, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier10 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf11 = make_pipeline(fee, mlp, memory=memory)\n",
    "scores = cross_val_score(clf11, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier12 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN  # K 近邻\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC  # 决策树\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC  # 随机森林\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ETC  # 极端随机森林\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn = KNN(n_neighbors=3)\n",
    "dtc = DTC(min_samples_split=3)\n",
    "rfc = RFC(n_estimators=100)\n",
    "etc = ETC(n_estimators=100)\n",
    "\n",
    "clf4 = make_pipeline([('fee', fee),('clf', knn)], memory=memory)\n",
    "# 创建参数网格\n",
    "param_grid = {\n",
    "    'clf__n_neighbors': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 实例化GridSearchCV\n",
    "grid_search = GridSearchCV(clf4, param_grid=param_grid)\n",
    "scores = cross_val_score(grid_search, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier4 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "scores = cross_val_score(clf4, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier4 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf5 = make_pipeline(fee, dtc, memory=memory)\n",
    "scores = cross_val_score(clf5, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier5 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf6 = make_pipeline(fee, rfc, memory=memory)\n",
    "scores = cross_val_score(clf6, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier6 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf7 = make_pipeline(fee, etc, memory=memory)\n",
    "scores = cross_val_score(clf7, data, label, cv=cv, n_jobs=15)\n",
    "print(\"classifier7 Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning import TS\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN  # K 近邻\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC  # 决策树\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC  # 随机森林\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ETC  # 极端随机森林\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import Memory\n",
    "# 设置缓存目录\n",
    "cachedir = 'my_cache_directory'\n",
    "memory = Memory(cachedir, verbose=0)\n",
    "\n",
    "fee = TS()\n",
    "knn = KNN(n_neighbors=3)\n",
    "dtc = DTC(min_samples_split=3)\n",
    "rfc = RFC(n_estimators=100)\n",
    "etc = ETC(n_estimators=100)\n",
    "\n",
    "pipe = Pipeline([('fee', fee),('clf', rfc)], memory=memory)\n",
    "# 创建参数网格\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [20, 50, 100],\n",
    "    'clf__max_depth': [5, 10, 20],\n",
    "    'clf__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# 实例化GridSearchCV\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=cv, n_jobs=15)\n",
    "grid_search.fit(data, label)\n",
    "\n",
    "# 获取所有参数组合的评估结果\n",
    "cv_results = grid_search.cv_results_\n",
    "for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
    "    print(f\"{mean_score:.3f} for {params}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 假设 'data' 是您的特征数据，'label' 是标签\n",
    "# 'cv' 是交叉验证策略，例如 KFold 或 StratifiedKFold\n",
    "\n",
    "# 设置管道和参数网格\n",
    "knn = KNeighborsClassifier()\n",
    "pipe = Pipeline([('fee', fee),('clf', knn)], memory=memory)\n",
    "param_grid = {'clf__n_neighbors': [3, 5, 7]}\n",
    "\n",
    "# 实例化 GridSearchCV\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid)\n",
    "\n",
    "# 使用 cross_val_score 来执行交叉验证\n",
    "# 注意：这里我们设置 return_estimator=True 来返回每个折叠的估计器\n",
    "cv_results = cross_validate(grid_search, data, label, cv=cv, n_jobs=15, return_estimator=True)\n",
    "\n",
    "# Access the estimator from each fold\n",
    "for fold, estimator in enumerate(cv_results['estimator']):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"Best parameters: {estimator.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {estimator.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transfer_learning.tl_classifier import TL_Classifier\n",
    "from joblib import Memory\n",
    "\n",
    "# 设置缓存目录\n",
    "cachedir = 'my_cache_directory'\n",
    "memory = Memory(cachedir, verbose=0)\n",
    "\n",
    "classifier = TL_Classifier(memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
