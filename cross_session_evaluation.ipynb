{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Session on Multiple Datasets\n",
    "Author: LC.Pan  \n",
    "Date: 2024-06-24  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 公共工具库\n",
    "import os, time\n",
    "import json\n",
    "import numpy as np\n",
    "import itertools\n",
    "import multiprocessing as mp\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "import torch\n",
    "\n",
    "# 私有工具库\n",
    "from loaddata import Dataset_Left_Right_MI\n",
    "from deep_learning.dl_classifier import DL_Classifier\n",
    "from pre_processing.preprocessing import Pre_Processing\n",
    "from transfer_learning.tl_classifier import TL_Classifier\n",
    "from transfer_learning import TLSplitter, encode_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数\n",
    "dataset_name = 'Pan2023'\n",
    "fs = 250\n",
    "freqband = [8,30]\n",
    "datapath = r'E:\\工作进展\\小论文2023会议\\数据处理python\\datasets'\n",
    "\n",
    "# 加载数据\n",
    "dataset = Dataset_Left_Right_MI(dataset_name,fs,fmin=freqband[0],fmax=freqband[1],tmin=0,tmax=4,path=datapath)\n",
    "\n",
    "# for sub in dataset.subjects:\n",
    "#     print(f\"Subject {sub}...\")\n",
    "#     # 加载数据\n",
    "#     data = dataset.get_data()\n",
    "\n",
    "sub = [1]\n",
    "data,label,info = dataset.get_data(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_values = info['session'].unique()\n",
    "print('the session values are:',session_values)\n",
    "session_indices = info.groupby('session').apply(lambda x: x.index.tolist())\n",
    "\n",
    "# 将结果转换为字典，键为不同值，值为对应的索引列表\n",
    "session_index_dict = dict(zip(session_values, session_indices))\n",
    "\n",
    "Data, Label=[], []\n",
    "for session in session_values[:2]:\n",
    "    Data.append(data[session_index_dict[session]])\n",
    "    Label.append(label[session_index_dict[session]])\n",
    "\n",
    "X, y_enc, domain =encode_datasets(Data, Label)\n",
    "print(X.shape, y_enc.shape, len(domain))\n",
    "print(domain)\n",
    "\n",
    "target_domain = domain[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置基于迁移学习的跨会话交叉验证评估索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "cv = StratifiedShuffleSplit(n_splits=10, random_state=42)\n",
    "tl_cv = TLSplitter(target_domain=target_domain, cv=cv, no_calibration=False)\n",
    "train_size = 30\n",
    "\n",
    "if train_size == 0:\n",
    "    tl_cv.no_calibration = True\n",
    "else:\n",
    "    tl_cv.cv.train_size = train_size\n",
    "\n",
    "for train, test in tl_cv.split(X, y_enc):\n",
    "    print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Memory\n",
    "\n",
    "# 设置缓存目录\n",
    "cachedir = '../my_cache_directory'\n",
    "memory = Memory(cachedir, verbose=0)\n",
    "\n",
    "preprocess = Pre_Processing(fs_new=160, fs_old=250, \n",
    "                       n_channels=None, \n",
    "                       start_time=0.5, end_time=3.5,\n",
    "                       lowcut=None, highcut=None, )\n",
    "\n",
    "Model = TL_Classifier(dpa_method='EA', \n",
    "                      fee_method='CSP', \n",
    "                      fes_method='MIC-K', \n",
    "                      clf_method='SVM',\n",
    "                      pre_est=preprocess.process,\n",
    "                      memory=memory,\n",
    "                      target_domain=target_domain,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating cross-session performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "scores = cross_validate(Model, X, y_enc, cv=tl_cv, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time = scores['fit_time']\n",
    "test_time = scores['score_time']\n",
    "test_score = scores['test_score']\n",
    "print('train time: %.3f s, test time: %.3f s' % (train_time.mean(), test_time.mean()))\n",
    "print('test score: %.3f +/- %.3f' % (test_score.mean(), test_score.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
