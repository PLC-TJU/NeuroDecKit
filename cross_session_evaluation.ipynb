{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Session on Multiple Datasets\n",
    "Author: LC.Pan  \n",
    "Date: 2024-06-24  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import json\n",
    "import numpy as np\n",
    "import itertools\n",
    "import multiprocessing as mp\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "import torch\n",
    "\n",
    "# 私有工具库\n",
    "from loaddata import Dataset_Left_Right_MI\n",
    "from deep_learning.dl_classifier import DL_Classifier\n",
    "from pre_processing.preprocessing import Pre_Processing\n",
    "from transfer_learning.tl_classifier import TL_Classifier\n",
    "from transfer_learning import TLSplitter, encode_datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数\n",
    "dataset_name = 'Pan2023'\n",
    "fs = 250\n",
    "freqband = [8,30]\n",
    "datapath = r'E:\\工作进展\\小论文2023会议\\数据处理python\\datasets'\n",
    "\n",
    "# 加载数据\n",
    "dataset = Dataset_Left_Right_MI(dataset_name,fs,fmin=freqband[0],fmax=freqband[1],tmin=0,tmax=4,path=datapath)\n",
    "\n",
    "# for sub in dataset.subjects:\n",
    "#     print(f\"Subject {sub}...\")\n",
    "#     # 加载数据\n",
    "#     data = dataset.get_data()\n",
    "\n",
    "sub = [1]\n",
    "data,label,info = dataset.get_data(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_values = info['session'].unique()\n",
    "print('the session values are:',session_values)\n",
    "session_indices = info.groupby('session').apply(lambda x: x.index.tolist())\n",
    "\n",
    "# 将结果转换为字典，键为不同值，值为对应的索引列表\n",
    "session_index_dict = dict(zip(session_values, session_indices))\n",
    "\n",
    "Data, Label=[], []\n",
    "for session in session_values[:2]:\n",
    "    Data.append(data[session_index_dict[session]])\n",
    "    Label.append(label[session_index_dict[session]])\n",
    "\n",
    "X, y_enc, domain =encode_datasets(Data, Label)\n",
    "print(X.shape, y_enc.shape, len(domain))\n",
    "print(domain)\n",
    "\n",
    "target_domain = domain[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置基于迁移学习的跨会话交叉验证评估索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "cv = StratifiedShuffleSplit(n_splits=3, random_state=42)\n",
    "tl_cv = TLSplitter(target_domain=target_domain, cv=cv, no_calibration=False)\n",
    "train_size = 30\n",
    "\n",
    "if train_size == 0:\n",
    "    tl_cv.no_calibration = True\n",
    "else:\n",
    "    tl_cv.cv.train_size = train_size\n",
    "\n",
    "for train, test in tl_cv.split(X, y_enc):\n",
    "    print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Memory\n",
    "\n",
    "# 设置缓存目录\n",
    "cachedir = '../my_cache_directory'\n",
    "memory = Memory(cachedir, verbose=0)\n",
    "\n",
    "preprocess = Pre_Processing(fs_new=160, fs_old=250, \n",
    "                       n_channels=None, \n",
    "                       start_time=0.5, end_time=3.5,\n",
    "                       lowcut=None, highcut=None, )\n",
    "\n",
    "Model = TL_Classifier(dpa_method='EA', \n",
    "                      fee_method='CSP', \n",
    "                      fes_method='MIC-K', \n",
    "                      clf_method='SVM',\n",
    "                      pre_est=preprocess.process,\n",
    "                      memory=memory,\n",
    "                      target_domain=target_domain,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transfer_learning.algorithms import  Algorithms\n",
    "\n",
    "# 设置缓存目录\n",
    "cachedir = '../my_cache_directory'\n",
    "\n",
    "preprocess = Pre_Processing(fs_new=160, fs_old=250, \n",
    "                       n_channels=None, \n",
    "                       start_time=0.5, end_time=3.5,\n",
    "                       lowcut=None, highcut=None, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating cross-session performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "scores = cross_validate(Model, X, y_enc, cv=tl_cv, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time = scores['fit_time']\n",
    "test_time = scores['score_time']\n",
    "test_score = scores['test_score']\n",
    "print('train time: %.3f s, test time: %.3f s' % (train_time.mean(), test_time.mean()))\n",
    "print('test score: %.3f +/- %.3f' % (test_score.mean(), test_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "DPA_METHODS = ['TLDummy', 'EA', 'RA', 'RPA']\n",
    "FEE_METHODS = [None,'CSP', 'TRCSP', 'MDM', 'FGMDM', 'TS']\n",
    "FES_METHODS = [None, 'ANOVA-F-K', 'ANOVA-F-P', 'MIC-K', 'MIC-P', 'PCA', 'LASSO', 'RFE', 'RFECV']\n",
    "CLF_METHODS = [None, 'SVM', 'LDA', 'LR', 'KNN', 'DTC', 'RFC', 'ETC', 'ABC', 'GBC', 'GNB', 'MLP', 'XGBoost', 'CatBoost', 'LightGBM']\n",
    "END_METHODS = [None,'RKNN', 'RKSVM', 'ABC-MDM', 'ABC-FGMDM', 'ABC-TSSVM', 'ABC-TSLDA', 'ABC-TSLR', 'MDWM', 'MEKT']\n",
    "END_TO_END_METHODS = [None,'TRCA', 'DCPM', 'SBLEST']\n",
    "\n",
    "# 所有方法的组合\n",
    "all_alg_list = \n",
    "\n",
    "## 挑选的部分方法组合\n",
    "dpa_list = [0, 1, 2, 3] # 0: TLDummy, 2: EA, 3: RA, 4: RPA\n",
    "fee_list = [0, 1, 5] # 0: None, 1: CSP, 5: TS\n",
    "fes_list = [0, 4, 6, 8] # 0: None, 4: MIC-P, 6: LASSO, 8: RFECV\n",
    "clf_list = [0, 1, 2, 3, 11] # 0: None, 1: SVM, 2: LDA, 3: LR, 11: MLP\n",
    "end_list = [0, 5, 6, 7, 8, 9] # 0: None, 5: ABC-TSSVM, 6: ABC-TSLDA, 7: ABC-TSLR, 8: MDWM, 9: MEKT\n",
    "end_to_end_list = [0, 1, 2, 3] # 0: None, 1: TRCA, 2: DCPM, 3: SBLEST\n",
    "\n",
    "all_clf_list1 = list(itertools.product(\n",
    "    dpa_list, # 0: TLDummy, 2: EA, 3: RA, 4: RPA\n",
    "    fee_list, # 0: None, 1: CSP, 5: TS\n",
    "    fes_list, # 0: None, 4: MIC-P, 6: LASSO, 8: RFECV\n",
    "    clf_list, # 0: None, 1: SVM, 2: LDA, 3: LR, 11: MLP\n",
    "    [0], # 0: None\n",
    "    [0], # 0: None\n",
    "    ))\n",
    "\n",
    "all_clf_list2 = list(itertools.product(\n",
    "    dpa_list, \n",
    "    [0], # 0: None\n",
    "    [0], # 0: None\n",
    "    [0], # 0: None\n",
    "    end_list, # 0: None, 5: ABC-TSSVM, 6: ABC-TSLDA, 7: ABC-TSLR, 8: MDWM, 9: MEKT\n",
    "    [0], # 0: None\n",
    "    ))\n",
    "\n",
    "all_clf_list3 = list(itertools.product(\n",
    "    dpa_list, \n",
    "    [0], # 0: None\n",
    "    [0], # 0: None\n",
    "    [0], # 0: None\n",
    "    [0], # 0: None\n",
    "    end_to_end_list, # 0: None, 1: TRCA, 2: DCPM, 3: SBLEST\n",
    "    ))\n",
    "\n",
    "all_clf_list = all_clf_list1 + all_clf_list2 + all_clf_list3\n",
    "\n",
    "# 将all_clf_list中的所有方法编号转换为方法名称存入字典  \n",
    "# 方法名称串联：编号\n",
    "algorithm_dict = {}\n",
    "for i in range(len(all_clf_list)):  \n",
    "    # 关键字为对应各方法名称的串联（用“-”分隔） ，值为方法编号列表 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取Excel文件\n",
    "df = pd.read_(r'transfer_learning\\algorithms_part.csv', sheet_name='algor-list')\n",
    "\n",
    "# 提取G5:G154和V5:V154的数据\n",
    "g_values = df['KEY'].iloc[0:150]  # 0基数，所以从4开始到155结束\n",
    "v_values = df['ID'].iloc[0:150]\n",
    "\n",
    "# 将v_values中的字符串转化为int类型\n",
    "v_values = [eval(i) for i in v_values]\n",
    "\n",
    "# 创建字典\n",
    "key_value_pairs = dict(zip(g_values, v_values))\n",
    "\n",
    "# 输出字典\n",
    "print(key_value_pairs)\n",
    "\n",
    "# 保存字典为csv文件\n",
    "df = pd.DataFrame(key_value_pairs.items(), columns=['KEY', 'ID'])\n",
    "df.to_csv('transfer_learning/key_value_pairs.csv', index=False)\n",
    "\n",
    "# 读取csv文件\n",
    "df = pd.read_csv('transfer_learning/key_value_pairs.csv')\n",
    "\n",
    "# 输出csv文件内容\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "# 读取csv文件\n",
    "df = pd.read_csv('transfer_learning/algorithms_part.csv')\n",
    "\n",
    "# 遍历csv文件，计算每个方法的准确率\n",
    "for i in range(100, len(df)):#range(len(df)):\n",
    "    # 读取当前行的key和value\n",
    "    key = df.loc[i, 'Algorithms']\n",
    "    value = df.loc[i, 'Algorithm_ID']\n",
    "    value = eval(value)\n",
    "    # 实例化模型\n",
    "    Model = Algorithms(\n",
    "    algorithm_id=value, \n",
    "    target_domain=target_domain, \n",
    "    pre_processing=preprocess.process, \n",
    "    memory_location=cachedir\n",
    "    )\n",
    "    # 读取当前行的准确率\n",
    "    scores = cross_validate(Model, X, y_enc, cv=tl_cv, n_jobs=-1)\n",
    "    train_time = scores['fit_time']\n",
    "    test_time = scores['score_time']\n",
    "    test_score = scores['test_score']\n",
    "    # 写入当前行的准确率\n",
    "    df.loc[i, 'accuracy'] = test_score.mean()\n",
    "    df.loc[i, 'train_time'] = train_time.mean()\n",
    "    df.loc[i, 'test_time'] = test_time.mean()\n",
    "    print(f\"{i+1}. Method {key} has an accuracy of {test_score.mean():.2f} +/- {test_score.std():.2f}\")\n",
    "\n",
    "# 输出计算后的csv文件内容\n",
    "print(df)\n",
    "\n",
    "\n",
    "# 保存所有方法和准确率的到csv文件\n",
    "df.to_csv('transfer_learning/algorithms_part.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "value = [0,4,0,0,0,0]\n",
    "\n",
    "# 实例化模型\n",
    "Model = Algorithms(\n",
    "algorithm_id=value, \n",
    "target_domain=target_domain, \n",
    "pre_processing=preprocess.process, \n",
    "memory_location=cachedir\n",
    ")\n",
    "# 读取当前行的准确率\n",
    "acc = []\n",
    "for train, test in tl_cv.split(X, y_enc):\n",
    "    X_train, y_train = X[train], y_enc[train]\n",
    "    X_test, y_test = X[test], y_enc[test]\n",
    "    Model.fit(X_train, y_train)\n",
    "    score = Model.score(X_test, y_test)\n",
    "    acc.append(score)\n",
    "    print(\"Score: %0.2f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('transfer_learning/algorithms_part.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
